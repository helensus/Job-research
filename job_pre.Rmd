---
title: "Job research about data scientists"
author: "Helen"
date: "12/13/2020"
  revealjs::revealjs_presentation:
    theme: solarized
    highlight: pygments
    css: leaflet-reveal.css
    center: false
    transition: slide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(magrittr)
library(stringr)
library(tidytext)
library(ggplot2)
```


```{r , echo= FALSE}
list_org <- read.csv("listings2.csv")

## tidy text with unnest_tokens(), take each word into a token
data(stop_words)
tidy_list<- list_org%>% unnest_tokens(word,description) %>%
  anti_join(stop_words) #remove stop words
```

# Introduction
This project is about utilizing text mining in R. Since we are going to find a job of data scientist or statistical job, it is important for us to know about what features the interviewers are looking for. Data is crawled from Indeed website that is for job listings.

Here I mainly focus on the following 3 questions:

1.How many job opportunities area there for data scientists and statistical analysists?

2.What skills do the positions require?

3.Are there any similarities and differences between the descriptions of jobs in two different areas?

# Data crawled

```{r echo=FALSE}
kable(list_org[1:5,2:6])
```
Here is a script from the data crawled from the website Indeed.


------
# Location Distribution
### List the top 10 states with the most job positions of data scientists
The plot shows that MA has the most positions of data scientists, which is not a display of the whole job listing.The reason of having Masachussette ranking 1st might for the location of crawling is at Boston, MA. So my analysis will turn to analysis the job opportunities near my current coordinate.
```{r echo=FALSE, message=FALSE, warning=FALSE}
#area
cityjob<-list_org %>% 
  separate(location, into=c("area","state"),sep=",") %>%
  filter(!is.na(state)) %>%
  group_by(state,area)%>%summarise(count = n())%>%arrange(desc(count))
kable(cityjob[2:6,])
## List the top 10 states with the most job positions of data scientists
list_org %>% 
  separate(location, into=c("area","state"),sep=",") %>%
  filter(!is.na(state)) %>%
  count(state, sort=TRUE) %>% 
  mutate(state= reorder(state,n)) %>%
  head(10) %>%
  ggplot(aes(state,n)) +
  geom_col() +
  labs(y=NULL)
```
-----
# List the top 10 companies with the most job positions of data scientists
```{r, echo=FALSE}
companyjob<-list_org %>%
  filter(!is.na(company)) %>%
  group_by(companyt)%>%summarise(count = n())%>%arrange(desc(count))
kable(companyjob[2:6,])

list_org %>%
  filter(!is.na(company)) %>%
  count(company, sort=TRUE) %>% 
  mutate(company= reorder(company,n)) %>%
  head(10) %>%
  ggplot(aes(company,n)) +
  geom_col() +
  labs(y=NULL) + ylab("Position") +xlab("Company")+
  theme(axis.text.x = element_text(size = 12, color = "darkblue", vjust = 0.5, hjust = 0.5, angle = 45))
```


## Description
Looking at the description of jobs, I want to know how areWord Cloud
```{r, echo=FALSE}
library(wordcloud2) 
freq<- list_org %>% unnest_tokens(word,description) %>%
  anti_join(stop_words)  %>%
  mutate(word = str_extract(word, "[a-z']+"))   %>% count(word)
wordcloud2(data=freq, size=1.6, color='random-dark', shape="star")
```

## The most 10 common words in description 
```{r}
# plot the most 10 common words in description
tidy_list %>%
  count(word, sort=TRUE) %>% 
   mutate(word= reorder(word,n)) %>%
    filter(!is.na(word)) %>%
    head(10) %>%
     ggplot(aes(n, word)) +
     geom_col() +
     labs(y=NULL)
```

## Words appear together
Some words may come together. The following plot shows common bigrams of words, showing those that occurred more than 3 times and where neither word was a stop word
```{r, echo= FALSE}
library(ggraph)  #devtools::install_github('thomasp85/ggraph')
library(igraph)
count_bigrams <- function(dataset) {
  dataset %>%
    unnest_tokens(bigram, description, token = "ngrams", n = 2) %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(!word1 %in% stop_words$word,
           !word2 %in% stop_words$word) %>%
    count(word1, word2, sort = TRUE)
}

visualize_bigrams <- function(bigrams) {
  set.seed(2016)

  bigrams %>%
    ggraph (layout = "fr") +
    geom_edge_link() +
    geom_node_point(color = "lightpink", size = 5) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1)
}
#take it to the text-list_org
list_org %>%
  count_bigrams()%>%
  filter(n > 3 & !is.na(word1) & !is.na(word2)) %>%
  graph_from_data_frame() %>%
  visualize_bigrams()
```

#the descriptions of jobs in two different areas
As my location is at Boston, I want to look at the job descriptions of the different areas nearby. The plot shows the comparison the word frequencies of Boston, Cambridge and Framingham.
```{r, echo=FALSE}
#plot of word frequencies: boston compare with Cambridge and Framingham
#take out the lines needed
location_compare <-tidy_list  %>%
  separate(location, into=c("area","state"),sep=",") %>%
  filter(!is.na(area)) %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  filter(area =="Boston"|area =="Framingham"|area=="Cambridge") %>%
  count(area, word) %>%
  group_by(area)%>%
  mutate(proportion= n/ sum(n)) %>% select(-n)%>%
  spread(area, proportion) %>%
  gather(area,proportion, `Framingham`:`Cambridge`) 


library(scales)
#plot
ggplot(location_compare, aes(x = proportion, y = `Boston`, 
                      color = abs(`Boston` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "darkslategray4", high = "gray75") +
  facet_wrap(~area, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "Boston", x = NULL)
```

# Conclusion

We found some advantages and disadvantages of looking for a data science and statistical job through this project. The advantage is that we all have strong teamwork and communication skills. This is due to the fact that we have been working as a team during the graduate study at BU MSSP. Another advantage is that our expertise is well matched. Including the text mining I used this time, the modeling skills I learned in class 678, and the machine learning I will learn in class 679 next semester. Our disadvantage is that we don't have enough work experience. Most of our jobs require two years of working experience.

