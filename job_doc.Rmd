---
title: "Job research about data scientists"
author: "Haoran su"
date: "12/14/2020"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(magrittr)
library(stringr)
library(tidytext)
library(ggplot2)
library(knitr)
```


```{r,echo=FALSE, message=FALSE, warning=FALSE}
list_org <- read.csv("listings2.csv")

## tidy text with unnest_tokens(), take each word into a token
data(stop_words)
tidy_list<- list_org%>% unnest_tokens(word,description) %>%
  anti_join(stop_words) #remove stop words
```

# Introduction
This project is about utilizing text mining in R. Since we are going to find a job of data scientist or statistical job, it is important for us to know about what features the interviewers are looking for. Data is crawled from Indeed website that is for job listings.

Here I mainly focus on the following 3 questions:

1.How many job opportunities area there for data scientists and statistical analysists?

2.What skills do the positions require?

3.Are there any similarities and differences between the descriptions of jobs in two different areas?

## Data crawled

Here is a script from the data crawled.
```{r echo=FALSE}
kable(list_org[1:5,2:5])
```



# Location Distribution
## List the top 10 states with the most job positions of data scientists
<font size ="4">The plot shows that MA has the most positions of data scientists, which is not a display of the whole job listing.The reason of having Masachussette ranking 1st might for the location of crawling is at Boston, MA. So my analysis will turn to analysis the job opportunities near my current coordinate.</font>
```{r,echo=FALSE, message=FALSE, warning=FALSE, fig.height=2.5,fig.width=4}
#area
cityjob<-list_org %>% 
  separate(location, into=c("area","state"),sep=",") %>%
  filter(!is.na(state)) %>%
  group_by(state,area)%>%summarise(count = n())%>%arrange(desc(count))
kable(cityjob[2:6,])
## List the top 10 states with the most job positions of data scientists
list_org %>% 
  separate(location, into=c("area","state"),sep=",") %>%
  filter(!is.na(state)) %>%
  count(state, sort=TRUE) %>% 
  mutate(state= reorder(state,n)) %>%
  head(10) %>%
  ggplot(aes(state,n)) +
  geom_col() +
  labs(y=NULL)
```

## List the top 10 companies with the most job positions of data scientists
```{r,echo=FALSE, message=FALSE, warning=FALSE, fig.height=4}
companyjob<-list_org %>%
  filter(!is.na(company)) %>%
  group_by(company)%>%summarize(count = n())%>%arrange(desc(count))
kable(companyjob[2:6,])

list_org %>%
  filter(!is.na(company)) %>%
  count(company, sort=TRUE) %>% 
  mutate(company= reorder(company,n)) %>%
  head(10) %>%
  ggplot(aes(company,n)) +
  geom_col() +
  labs(y=NULL) + ylab("Position") +xlab("Company")+
  theme(axis.text.x = element_text(size = 12, color = "darkblue", vjust = 0.5, hjust = 0.5, angle = 45))
```


# Description
Looking at the description of jobs, I want to know "what skills do the positions require".

## Word Cloud
```{r,echo=FALSE, message=FALSE, warning=FALSE}
library(wordcloud2) 
freq<- list_org %>% unnest_tokens(word,description) %>%
  anti_join(stop_words)  %>%
  mutate(word = str_extract(word, "[a-z']+"))   %>% count(word)
wordcloud2(data=freq, size=1.6, color='random-dark', shape="star")
```
From the word cloud, I found that the words appear most frequently is "business, science, skills, development". It surprised me that the word "business" appear larger than "science". My interpretation is that the companies focus more on business value, talents' ability to realize talent. 

And I didn't expect so many references to words " development" in the job descriptions. It might show that the employers are looking for long-term contribution of employees, who are expected to have the ability to learn. I think I need to prepare examples that show my self-learning ability.

During the completion of this project, I expanded to discover many r's abilities, I learned from the examples in the book, the discussions that came up with google searching, retrieving how the functions I wanted to implement and the problems I had to solve.

## The most 10 common words in description 
```{r,echo=FALSE, message=FALSE, warning=FALSE}
# plot the most 10 common words in description
tidy_list %>%
  count(word, sort=TRUE) %>% 
   mutate(word= reorder(word,n)) %>%
    filter(!is.na(word)) %>%
    head(10) %>%
     ggplot(aes(n, word)) +
     geom_col() +
     labs(y=NULL)
```

# Words appear together
Some words may come together. The following plot shows common bigrams of words, showing those that occurred more than 3 times and where neither word was a stop word
```{r,echo=FALSE, message=FALSE, warning=FALSE}
library(ggraph)  #devtools::install_github('thomasp85/ggraph')
library(igraph)
count_bigrams <- function(dataset) {
  dataset %>%
    unnest_tokens(bigram, description, token = "ngrams", n = 2) %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(!word1 %in% stop_words$word,
           !word2 %in% stop_words$word) %>%
    count(word1, word2, sort = TRUE)
}

visualize_bigrams <- function(bigrams) {
  set.seed(2016)

  bigrams %>%
    ggraph (layout = "fr") +
    geom_edge_link() +
    geom_node_point(color = "lightpink", size = 5) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1)
}
#take it to the text-list_org
list_org %>%
  count_bigrams()%>%
  filter(n > 3 & !is.na(word1) & !is.na(word2)) %>%
  graph_from_data_frame() %>%
  visualize_bigrams()
```

# The descriptions of jobs in two different areas
As my location is at Boston, I want to look at the job descriptions of the different areas nearby. The plot shows the comparison the word frequencies of Boston, Cambridge and Framingham.
```{r,echo=FALSE, message=FALSE, warning=FALSE}
#plot of word frequencies: boston compare with Cambridge and Framingham
#take out the lines needed
location_compare <-tidy_list  %>%
  separate(location, into=c("area","state"),sep=",") %>%
  filter(!is.na(area)) %>%
  mutate(word = str_extract(word, "[a-z']+")) %>%
  filter(area =="Boston"|area =="Framingham"|area=="Cambridge") %>%
  count(area, word) %>%
  group_by(area)%>%
  mutate(proportion= n/ sum(n)) %>% select(-n)%>%
  spread(area, proportion) %>%
  gather(area,proportion, `Framingham`:`Cambridge`) 


library(scales)
#plot
ggplot(location_compare, aes(x = proportion, y = `Boston`, 
                      color = abs(`Boston` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "darkslategray4", high = "gray75") +
  facet_wrap(~area, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "Boston", x = NULL)
```

# Conclusion

We found some advantages and disadvantages of looking for a data science and statistical job through this project. The advantage is that we all have strong teamwork and communication skills. This is due to the fact that we have been working as a team during the graduate study at BU MSSP. Another advantage is that our expertise is well matched. Including the text mining I used this time, the modeling skills I learned in class 678, and the machine learning I will learn in class 679 next semester. Our disadvantage is that we don't have enough work experience. Most of our jobs require two years of working experience.

